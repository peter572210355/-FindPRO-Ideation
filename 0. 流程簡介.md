推薦系統評估流程

在建立與驗證推薦演算法時，建議採用三層次流程（Tiered Evaluation）。
這樣能兼顧 離線檢查 → 人機評估 → 真實使用者影響，逐層增加信度與實用性。

⸻

Tier 1：離線評估（基本檢查）

以「歷史參考集合」作為比對基準，檢查推薦演算法是否合理並具穩定性。
	•	主要指標：g-Success@K、g-th Relevant Rank
	•	方法：計算平均數、變異數、分布；搭配 Bootstrap 估計信賴區間
	•	延伸：測試不同 K 值 (K-grid)、分領域 vs 總體表現、多樣性 (Entropy)
	•	目的：快速確認演算法至少在合理範圍，並提供 UI 顯示長度與後續改進依據


⸻

Tier 2：人機互動評估（衡量品質）

這一層是衡量推薦品質的關鍵，能產生更可靠的「金標」。

👉 方法：
	1.	對一組真實研究計畫產生 Top-K 推薦清單。
	2.	組成領域專家小組（理想成員：現任或前任召集人）。
	3.	呈現計畫與匿名化的推薦名單（不顯示分數或排名）。
	4.	請專家依相關度評分：
	•	1 = 無關
	•	2 = 牽強
	•	3 = 相關
	•	4 = 高度相關

👉 好處：
	•	高品質標註資料：專家評分比歷史名單更可靠，可當作真金標。
	•	更合適的指標：有了分級相關性分數後，可用 NDCG@K（Normalized Discounted Cumulative Gain），能獎勵「高度相關」的人排在前面。
	•	定性回饋：專家可提供質性原因，補足純量化的不足。

⚠️ 注意：這不是純量化任務，人類判斷很重要，需要和系統結合。

⸻

Tier 3：線上 A/B 測試（衡量影響）

最終層是衡量系統對真實使用者行為的影響，類似 Netflix／Spotify 的做法。

👉 方法：
	1.	在真實召集人群體中部署推薦系統。
	2.	紀錄完整的使用者互動行為。
	3.	當推出新演算法版本時，分流使用者：
	•	A 組 = 現有版本
	•	B 組 = 新演算法
	•	比較兩組行為差異。

👉 主要指標：
	•	採納率 (Adoption Rate)
	•	被召集人最終採納為委員的推薦候選人比例（相當於電商的「購買率」）。
	•	點擊率 (CTR)
	•	被點開檔案的候選人比例，反映使用者興趣。
	•	被採納候選人的平均排名
	•	使用者採納的候選人平均位於清單的第幾名？排名越前代表排序效果越好。
	•	單次會話成功率
	•	每次會話中至少採納一位候選人的比例。

⸻

✅ 這樣三層流程（離線 → 人機 → 線上）能讓系統評估更全面：
	•	Tier 1：快速檢查演算法是否「不離譜」。
	•	Tier 2：獲得高品質人工標註與專家意見。
	•	Tier 3：檢驗實際影響，決定演算法是否能帶來實質改善。
