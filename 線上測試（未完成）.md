Tier 3：線上 A/B 測試（衡量影響）

這是衡量系統對真實使用者行為影響的最終測試，與 Netflix／Spotify 類似。

方法：
在真實召集人群體中部署推薦系統。
完整紀錄使用者互動行為。
當推出新版本演算法時，將使用者分流到 B 組（新演算法）與 A 組（現有版本）進行比較。
主要指標：
採納率（Adoption Rate）：被召集人最終採納為委員的推薦候選人比例——這是最重要的指標，相當於電商的「購買」。
點擊率（CTR）：被點開檔案的推薦候選人比例，代表使用者興趣。
被採納候選人的平均排名：使用者採納的候選人平均位於推薦清單的哪裡？平均排名越低代表排序效果越好。
單次會話成功率：每次會話中至少採納一位推薦候選人的比例。


# 可紀錄事件
1) 互動事件（Behavior Events）
	•	Impression（曝光）：清單顯示一次就記一筆（含每個候選人的 rank）。
	•	View / Detail（查看詳情）：點開候選人頁面或展開卡片。
  • 查看到

   
	•	Click（點擊）：點超連結、按下「更多資訊」等。
	•	AddToCart（加入購物車）
	•	RemoveFromCart（從購物車移除）
	•	ReorderCart（在購物車內調整排序）
	•	Checkout / Submit（提交名單、產生面板）
	•	Feedback（顯性回饋）：喜歡/不喜歡、評分、理由標籤（例如「太資深/領域不合/利益衝突」）
	•	Dismiss / Hide（隱性負回饋）：略過、關閉、封鎖候選人
	•	Search / Filter Change（查詢與條件變更）
	•	Session End / Abandon（離開頁面或超時未動作）
# 基本指標

### 🔹 第一層：基本互動率
- **CTR (Click-Through Rate)** = 點擊數 / 曝光數  
- **Add-to-Cart Rate** = 加入購物車數 / 曝光數  
- **Adoption Rate（採納率 / Conversion Rate）** = 採納數 / 曝光數 或 採納數 / 加入購物車數  
- **Removal Rate** = 從購物車移除數 / 加入購物車數  

---

### 🔹 第二層：排名品質
- **Average Adopted Rank（平均採納排名）**：被採納候選人的平均名次  
- **MRR (Mean Reciprocal Rank)**：只看第一個正確答案（採納/點擊）的名次  
- **Precision@K**：前 K 名中正確候選人所占比例  
- **Recall@K / HitRate@K**：前 K 名內是否至少有一個正確答案  
- **NDCG@K**：同時考慮「相關性」與「排名折損」的指標  

---

### 🔹 第三層：行為漏斗與體驗
- **行為漏斗轉換率**：Impression → Click → AddToCart → Adopt 的各步驟轉換率  
  - Click-Through Conversion（曝光到點擊）  
  - Cart Conversion（點擊到加購）  
  - Adopt Conversion（加購到採納）  
- **時間指標**  
  - Time-to-First-Click（從曝光到第一次點擊的時間）  
  - Time-to-Adopt（從曝光到採納的時間）  
  - Dwell Time / Session Duration（停留時間 / 使用時長）  
- **Session-Level 指標**  
  - 平均互動數（每場次點擊、加購次數）  
  - Cart Size（購物車平均大小）  
  - Abandon Rate（開始但未採納就結束的比例）  
- **負回饋指標**  
  - Skip Rate（曝光後完全沒互動）  
  - Remove Rate（移除候選人比例）  
  - Hide/Dismiss Rate（隱藏/封鎖候選人比例）  

---

### 🔹 特殊延伸指標
- **多樣性 (Diversity)**：購物車或採納名單的領域分散程度（Category Diversity, ILD）  
- **新鮮度 (Novelty)**：使用者之前沒看過或沒互動過的候選人比例  
- **穩定 vs 探索 (Explore vs Exploit)**：分析 is_explore 候選人的表現  
- **回饋一致性 (Feedback Consistency)**：顯性評分 vs 實際採納的吻合度  
    

3) 候選人與清單屬性（Content & Ranking Features）
	•	candidate_id、name（必要的識別；個資請做最小化與脫敏）
	•	rank（顯示時的名次）
	•	score（模型分數；可記小數）
	•	features_snapshot（重要特徵快照或哈希，用於離線重現）
	•	list_id（此次推薦清單的 id）
	•	page / position（分頁與位置）
	•	is_explore（是否為探索流量/多樣性插入）
# 基本指標
## 候選人與清單屬性可衍生的指標

### 🔹 Rank（名次）
- **Average Adopted Rank（平均採納排名）**：被採納候選人的平均排序位置  
- **MRR (Mean Reciprocal Rank)**：只看第一個正確答案（採納/點擊）的名次  
- **Position Bias 分析**：不同名次的 CTR / 採納率，觀察用戶是否只偏好前幾名  

---

### 🔹 Score（模型分數）
- **Calibration（分數校準）**：比較 score 與實際採納率是否一致  
- **Score–Rank Correlation**：分數高低與實際排名、採納情況的相關性  
- **AUC / ROC / PR 曲線**：若有「正確 vs 不正確」標籤，可用來評估分數區分度  

---

### 🔹 features_snapshot（特徵快照）
- **重要特徵分布監控**：觀察被推薦 / 被採納候選人的特徵分布  
- **Feature Drift**：長期追蹤推薦時候選人特徵分布是否偏移  
- **特徵與行為相關性**：分析哪些特徵值的候選人更容易被點擊 / 採納  

---

### 🔹 list_id（清單 ID）
- **Per-List Coverage**：每個清單中被採納的候選人比例  
- **List-Level Conversion Rate**：整份清單的採納成功率  
- **AB 測試分流分析**：不同清單（不同演算法版本）間的採納率/CTR 差異  

---

### 🔹 page / position（分頁與位置）
- **Page-wise CTR / Conversion**：不同頁的點擊率、採納率  
- **Scroll Depth 分析**：使用者實際瀏覽到第幾頁  
- **Long-Tail Coverage**：後面頁的候選人是否還能被採納  

---

### 🔹 is_explore（探索插入）
- **Explore vs Exploit CTR / Adoption Rate**：探索流量 vs 穩定流量的效果比較  
- **Exploration Yield**：探索候選人最終被採納的比例  
- **Diversity Gain**：探索候選人是否提高了名單多樣性  
- **Risk–Reward Analysis**：探索候選人雖然 CTR 較低，但是否帶來長期收益  

---

### 🔹 綜合指標
- **NDCG@K / Precision@K / Recall@K**：需要 rank + score + ground truth  
- **Coverage（覆蓋率）**：被推薦候選人數 / 總候選人池數  
- **Novelty / Diversity**：結合 is_explore、features_snapshot 來計算  

5) 實驗與情境（Experiment & Context）
	•	ab_test_id / variant（A/B 測試版本）
	•	algorithm_version（演算法與特徵版本）
	•	request_id / session_id / user_id（會話識別；注意隱私）
	•	query / task_context（使用者輸入的題目、學門、關鍵詞）
	•	filters / constraints（排除條件、學門、年資、地域）
	•	device / browser / locale / latency_ms（效能與裝置）
	•	timestamp（ISO 時間）
6) 標註與真值（Labels / Outcomes）
	•	adopted = {0/1}（是否被最後採納）
	•	adoption_time（從推薦到採納的時間）
	•	conflict_flag（是否事後被標記利益衝突）
	•	quality_label（專家評分或事後審核標註）
	•	rejection_reason（未採納原因標籤）
.	max_rank_viewed
	•	使用者實際看過的最大名次（或最大頁數）。
	•	例：清單有 100 人，但用戶只滑到第 20 名 → max_rank_viewed = 20。
	2.	max_rank_clicked
	•	使用者點擊的候選人裡，排名最靠後的一個。
	•	例：用戶點擊了第 2 名和第 15 名 → max_rank_clicked = 15。
	3.	view_depth_ratio
	•	\frac{\text{max_rank_viewed}}{\text{list\_length}}
→ 看清單的比例深度。
	4.	click_depth_ratio
	•	\frac{\text{max_rank_clicked}}{\text{list\_length}}
→ 點擊的候選人相對於清單長度的深度。

⸻

🔹 可以衍生的指標
	•	Scroll Depth Distribution
	•	不同使用者的 max_rank_viewed 分布（平均、分位數）。
	•	Last-Click Position
	•	點擊最後一位候選人的名次統計，觀察用戶會不會翻到尾端才互動。
	•	Position Bias
	•	比較前段 vs 後段候選人的 CTR。
	•	Effective List Length
	•	平均 max_rank_viewed，代表實際有效的清單長度（例如推薦 100 人，但用戶平均只看 25 人）。
	•	Engagement Depth
	•	點擊數 vs max_rank_viewed 的比例，代表用戶在深度上的互動密度。


MAP（Mean Average Precision）： $\frac{1}{N}\sum_{i=1}^N \text{AP}_i$  
其中 $\text{AP}_i$ = 針對題目 $i$ 的 **平均精確度 (Average Precision)**，只在「命中位置」計算 Precision 再取平均。  
👉 白話：MAP 不只檢查有沒有命中，還會考慮「正確答案排得多前面」，越早出現貢獻越大。


NDCG@K：可採二元或分級相關性定義，依 ground truth 標註設計。
（可參考：https://yehjames.medium.com/python推薦系統-常見-線下-排序評估指標-90876d70a01 /）

是否可以用上述指標更改演算法權重
用戶打分vs用戶點擊
LOOVC arhr chr
